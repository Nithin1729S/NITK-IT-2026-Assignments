{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQRTiY3QACzF",
        "outputId": "66efabec-7b45-4272-a9bc-4555da032fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include<stdio.h>\n",
        "int main()\n",
        "{\n",
        "int devcount;\n",
        "cudaGetDeviceCount(&devcount);\n",
        "printf(\"Device count:%d\\n\",devcount);\n",
        "printf(\"hello\");\n",
        "for (int i = 0; i < devcount; ++i)\n",
        "{\n",
        "// Get device properties\n",
        "printf(\"\\nCUDA Device #%d\\n\", i);\n",
        "cudaDeviceProp devProp;\n",
        "cudaGetDeviceProperties(&devProp, i);\n",
        "printf(\"Name:%s\\n\", devProp.name);\n",
        "printf(\"Compute capability: %d.%d\\n\",devProp.major ,devProp.minor);\n",
        "printf(\"Warp Size %d\\n\",devProp.warpSize);\n",
        "printf(\"Total global memory:%u bytes\\n\",devProp.totalGlobalMem);\n",
        "printf(\"Total shared memory per block: %u bytes\\n\", devProp.sharedMemPerBlock);\n",
        "printf(\"Total registers per block : %d\\n\",devProp.regsPerBlock);\n",
        "printf(\"Clock rate: %d khz\\n\",devProp.clockRate);\n",
        "printf(\"Maximum threads per block:%d\\n\", devProp.maxThreadsPerBlock);\n",
        "for (int i = 0; i < 3; ++i)\n",
        "printf(\"Maximum dimension %d of block: %d\\n\", i, devProp.maxThreadsDim[i]);\n",
        "for (int i = 0; i <= 2; ++i)\n",
        "printf(\"Maximum dimension %d of grid: %d\\n\", i, devProp.maxGridSize[i]);\n",
        "printf(\"Number of multiprocessors:%d\\n\", devProp.multiProcessorCount);\n",
        "printf(\"max threads per multiprocessor: %d\\n\",devProp.maxThreadsPerMultiProcessor);\n",
        "}\n",
        "return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRu-NXtqAOBl",
        "outputId": "27d8b734-d561-4869-d327-c8fd9dd4a443"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device count:1\n",
            "hello\n",
            "CUDA Device #0\n",
            "Name:Tesla T4\n",
            "Compute capability: 7.5\n",
            "Warp Size 32\n",
            "Total global memory:2950758400 bytes\n",
            "Total shared memory per block: 49152 bytes\n",
            "Total registers per block : 65536\n",
            "Clock rate: 1590000 khz\n",
            "Maximum threads per block:1024\n",
            "Maximum dimension 0 of block: 1024\n",
            "Maximum dimension 1 of block: 1024\n",
            "Maximum dimension 2 of block: 64\n",
            "Maximum dimension 0 of grid: 2147483647\n",
            "Maximum dimension 1 of grid: 65535\n",
            "Maximum dimension 2 of grid: 65535\n",
            "Number of multiprocessors:40\n",
            "max threads per multiprocessor: 1024\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "__global__ void helloworld(void)\n",
        "{\n",
        "printf(\"Hello World from GPU\\n\");\n",
        "}\n",
        "int main() {\n",
        "helloworld<<<1,10>>>();\n",
        "printf(\"Hello World\\n\");\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "LX1N98M8AW2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a8bf89-c2d8-4199-d7ab-e3905e006a8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "__global__ void vecAdd(double *a, double *b, double *c, int n)\n",
        "{\n",
        "// Get global thread\n",
        "int id = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "// Do not go out of bounds\n",
        "if (id < n)\n",
        "c[id] = a[id] + b[id];\n",
        "}\n",
        "int main(int argc, char* argv[] )\n",
        "{\n",
        "// Size of vectors\n",
        "int n = 100;\n",
        "//time varibales\n",
        "struct timeval t1, t2;\n",
        "// Host input vectors\n",
        "double *h_a, *h_b;\n",
        "//Host output vector\n",
        "double *h_c;\n",
        "// Device input vectors\n",
        "double *d_a, *d_b;\n",
        "//Device output vector\n",
        "double *d_c;\n",
        "// Size, in bytes, of each vector\n",
        "size_t bytes = n*sizeof(double);\n",
        "// Allocate memory for each vector on host\n",
        "h_a = (double*)malloc(bytes);\n",
        "h_b = (double*)malloc(bytes);\n",
        "h_c = (double*)malloc(bytes);\n",
        "// Allocate memory for each vector on GPU\n",
        "cudaMalloc(&d_a, bytes);\n",
        "cudaMalloc(&d_b, bytes);\n",
        "cudaMalloc(&d_c, bytes);\n",
        "int i;\n",
        "// Initialize vectors on host\n",
        "for( i = 0; i < n; i++ ) {\n",
        "h_a[i] = i+1;\n",
        "h_b[i] = i+1;\n",
        "}\n",
        "// Copy host vectors to device\n",
        "cudaMemcpy( d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy( d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "gettimeofday(&t1, 0);\n",
        "\n",
        "// Execute the kernel\n",
        "vecAdd<<<1,100>>>(d_a, d_b, d_c, n);\n",
        "cudaDeviceSynchronize();\n",
        "gettimeofday(&t2, 0);\n",
        "\n",
        "// Copy array back to host\n",
        "cudaMemcpy( h_c, d_c, bytes, cudaMemcpyDeviceToHost );\n",
        "\n",
        "for(i=0; i<n; i=i+10)\n",
        "printf(\"c[%d]=%f\\n\",i,h_c[i]);\n",
        "double time = (1000000.0*(t2.tv_sec-t1.tv_sec) + t2.tv_usec-t1.tv_usec)/1000.0;\n",
        "\n",
        "printf(\"Time to generate: %3.10f ms \\n\", time);\n",
        "\n",
        "// Release device memory\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "// Release host memory\n",
        "free(h_a);\n",
        "free(h_b);\n",
        "free(h_c);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQPDB8l1n2Dq",
        "outputId": "0938d83d-40a2-4854-c216-a770a63da36a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c[0]=2.000000\n",
            "c[10]=22.000000\n",
            "c[20]=42.000000\n",
            "c[30]=62.000000\n",
            "c[40]=82.000000\n",
            "c[50]=102.000000\n",
            "c[60]=122.000000\n",
            "c[70]=142.000000\n",
            "c[80]=162.000000\n",
            "c[90]=182.000000\n",
            "Time to generate: 36.2510000000 ms \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "__global__ void vecAdd(double *a, double *b, double *c, int n)\n",
        "{\n",
        "// Get global thread\n",
        "int id = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "// Do not go out of bounds\n",
        "if (id < n)\n",
        "c[id] = a[id] + b[id];\n",
        "}\n",
        "int main(int argc, char* argv[] )\n",
        "{\n",
        "// Size of vectors\n",
        "int n = 100;\n",
        "//time varibales\n",
        "struct timeval t1, t2;\n",
        "// Host input vectors\n",
        "double *h_a, *h_b;\n",
        "//Host output vector\n",
        "double *h_c;\n",
        "// Device input vectors\n",
        "double *d_a, *d_b;\n",
        "//Device output vector\n",
        "double *d_c;\n",
        "// Size, in bytes, of each vector\n",
        "size_t bytes = n*sizeof(double);\n",
        "// Allocate memory for each vector on host\n",
        "h_a = (double*)malloc(bytes);\n",
        "h_b = (double*)malloc(bytes);\n",
        "h_c = (double*)malloc(bytes);\n",
        "// Allocate memory for each vector on GPU\n",
        "cudaMalloc(&d_a, bytes);\n",
        "cudaMalloc(&d_b, bytes);\n",
        "cudaMalloc(&d_c, bytes);\n",
        "int i;\n",
        "// Initialize vectors on host\n",
        "for( i = 0; i < n; i++ ) {\n",
        "h_a[i] = i+1;\n",
        "h_b[i] = i+1;\n",
        "}\n",
        "// Copy host vectors to device\n",
        "cudaMemcpy( d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy( d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "gettimeofday(&t1, 0);\n",
        "\n",
        "// Execute the kernel\n",
        "vecAdd<<<1,50>>>(d_a, d_b, d_c, n);\n",
        "cudaDeviceSynchronize();\n",
        "gettimeofday(&t2, 0);\n",
        "\n",
        "// Copy array back to host\n",
        "cudaMemcpy( h_c, d_c, bytes, cudaMemcpyDeviceToHost );\n",
        "\n",
        "for(i=0; i<n; i=i+10)\n",
        "printf(\"c[%d]=%f\\n\",i,h_c[i]);\n",
        "double time = (1000000.0*(t2.tv_sec-t1.tv_sec) + t2.tv_usec-t1.tv_usec)/1000.0;\n",
        "\n",
        "printf(\"Time to generate: %3.10f ms \\n\", time);\n",
        "\n",
        "// Release device memory\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "// Release host memory\n",
        "free(h_a);\n",
        "free(h_b);\n",
        "free(h_c);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWY_EC1toYu4",
        "outputId": "580eecce-8341-4e35-cf5d-6a1caac74688"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c[0]=2.000000\n",
            "c[10]=22.000000\n",
            "c[20]=42.000000\n",
            "c[30]=62.000000\n",
            "c[40]=82.000000\n",
            "c[50]=0.000000\n",
            "c[60]=0.000000\n",
            "c[70]=0.000000\n",
            "c[80]=0.000000\n",
            "c[90]=0.000000\n",
            "Time to generate: 0.2110000000 ms \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "__global__ void vecAdd(double *a, double *b, double *c, int n)\n",
        "{\n",
        "// Get global thread\n",
        "int id = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "// Do not go out of bounds\n",
        "if (id < n)\n",
        "c[id] = a[id] + b[id];\n",
        "}\n",
        "int main(int argc, char* argv[] )\n",
        "{\n",
        "// Size of vectors\n",
        "int n = 100;\n",
        "//time varibales\n",
        "struct timeval t1, t2;\n",
        "// Host input vectors\n",
        "double *h_a, *h_b;\n",
        "//Host output vector\n",
        "double *h_c;\n",
        "// Device input vectors\n",
        "double *d_a, *d_b;\n",
        "//Device output vector\n",
        "double *d_c;\n",
        "// Size, in bytes, of each vector\n",
        "size_t bytes = n*sizeof(double);\n",
        "// Allocate memory for each vector on host\n",
        "h_a = (double*)malloc(bytes);\n",
        "h_b = (double*)malloc(bytes);\n",
        "h_c = (double*)malloc(bytes);\n",
        "// Allocate memory for each vector on GPU\n",
        "cudaMalloc(&d_a, bytes);\n",
        "cudaMalloc(&d_b, bytes);\n",
        "cudaMalloc(&d_c, bytes);\n",
        "int i;\n",
        "// Initialize vectors on host\n",
        "for( i = 0; i < n; i++ ) {\n",
        "h_a[i] = i+1;\n",
        "h_b[i] = i+1;\n",
        "}\n",
        "// Copy host vectors to device\n",
        "cudaMemcpy( d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy( d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "gettimeofday(&t1, 0);\n",
        "\n",
        "// Execute the kernel\n",
        "vecAdd<<<2,50>>>(d_a, d_b, d_c, n);\n",
        "cudaDeviceSynchronize();\n",
        "gettimeofday(&t2, 0);\n",
        "\n",
        "// Copy array back to host\n",
        "cudaMemcpy( h_c, d_c, bytes, cudaMemcpyDeviceToHost );\n",
        "\n",
        "for(i=0; i<n; i=i+10)\n",
        "printf(\"c[%d]=%f\\n\",i,h_c[i]);\n",
        "double time = (1000000.0*(t2.tv_sec-t1.tv_sec) + t2.tv_usec-t1.tv_usec)/1000.0;\n",
        "\n",
        "printf(\"Time to generate: %3.10f ms \\n\", time);\n",
        "\n",
        "// Release device memory\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "// Release host memory\n",
        "free(h_a);\n",
        "free(h_b);\n",
        "free(h_c);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfPh6snRp6OZ",
        "outputId": "3bc5d9a2-d5c8-415b-b68e-7ed18dcdf9c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c[0]=2.000000\n",
            "c[10]=22.000000\n",
            "c[20]=42.000000\n",
            "c[30]=62.000000\n",
            "c[40]=82.000000\n",
            "c[50]=102.000000\n",
            "c[60]=122.000000\n",
            "c[70]=142.000000\n",
            "c[80]=162.000000\n",
            "c[90]=182.000000\n",
            "Time to generate: 0.2480000000 ms \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R99otyQprEaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
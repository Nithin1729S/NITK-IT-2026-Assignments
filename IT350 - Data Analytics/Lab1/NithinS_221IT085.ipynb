{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77548cd7-ad1d-42a7-8f7b-bb776022e4a8",
   "metadata": {},
   "source": [
    "# Scratch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240eefc2-20e6-4f02-adcc-797708afce1b",
   "metadata": {},
   "source": [
    "## Load the IRIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca936c3b-fe1e-4d12-935e-d266d8185b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the IRIS dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a34f8f-a820-4e10-a259-5bc98146f21d",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930535f9-60f5-449e-9694-3abb555df32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=42):\n",
    "    n_samples = len(X)\n",
    "    random.seed(random_state)\n",
    "    indices = list(range(n_samples))\n",
    "    random.shuffle(indices)\n",
    "    test_set_size = int(n_samples * test_size)\n",
    "    test_indices = indices[:test_set_size]\n",
    "    train_indices = indices[test_set_size:]\n",
    "    X_train = [X[i] for i in train_indices]\n",
    "    X_test = [X[i] for i in test_indices]\n",
    "    y_train = [y[i] for i in train_indices]\n",
    "    y_test = [y[i] for i in test_indices]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b0200-770e-4ff9-abb4-8b47bff63ba7",
   "metadata": {},
   "source": [
    "## Implement KNN Classifier from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b6484c0-0a3b-4c8a-a795-af3d964912df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return math.sqrt(sum((a - b) ** 2 for a, b in zip(x1, x2)))\n",
    "\n",
    "def predict(X_train, y_train, X_test, k):\n",
    "    predictions = []\n",
    "    for x in X_test:\n",
    "        distances = [(euclidean_distance(x, x_train), y_train[i]) for i, x_train in enumerate(X_train)]\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        k_nearest_labels = [label for _, label in distances[:k]]\n",
    "        most_common = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "        predictions.append(most_common)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a4e85-76b0-4af8-bab0-495c4ef43ba0",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f33788ea-71a4-4b52-b85a-150912f5fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score(y_true, y_pred):\n",
    "    true_positive = sum(1 for yt, yp in zip(y_true, y_pred) if yt == yp)\n",
    "    predicted_positive = len(y_pred)\n",
    "    return true_positive / predicted_positive\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    actual_positive = len(y_true)\n",
    "    true_positive = sum(1 for yt, yp in zip(y_true, y_pred) if yt == yp)\n",
    "    return true_positive / actual_positive\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct_predictions = sum(1 for yt, yp in zip(y_true, y_pred) if yt == yp)\n",
    "    return correct_predictions / len(y_true)\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    unique_labels = sorted(set(y_true))\n",
    "    matrix = [[0 for _ in unique_labels] for _ in unique_labels]\n",
    "    label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        matrix[label_to_index[yt]][label_to_index[yp]] += 1\n",
    "    return matrix\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    return precision, recall, f1, accuracy, conf_matrix\n",
    "\n",
    "def print_evaluation_metrics(precision, recall, f1, accuracy, conf_matrix):\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    for row in conf_matrix:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c044a8-2d8e-4d82-8792-2ee8356db488",
   "metadata": {},
   "source": [
    "##  Implement Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "617c5e4e-6923-47ac-b2e5-0e39426893a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(X, y, k_folds, random_state=42):\n",
    "    n_samples = len(X)\n",
    "    fold_size = n_samples // k_folds\n",
    "    random.seed(random_state)\n",
    "    indices = list(range(n_samples))\n",
    "    random.shuffle(indices)\n",
    "    folds = [indices[i*fold_size:(i+1)*fold_size] for i in range(k_folds)]\n",
    "    return folds\n",
    "\n",
    "def cross_validate(X, y, k_neighbors, k_folds=10):\n",
    "    folds = k_fold_split(X, y, k_folds)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for i in range(k_folds):\n",
    "        train_indices = [idx for j in range(k_folds) if j != i for idx in folds[j]]\n",
    "        test_indices = folds[i]\n",
    "        X_train = [X[idx] for idx in train_indices]\n",
    "        X_test = [X[idx] for idx in test_indices]\n",
    "        y_train = [y[idx] for idx in train_indices]\n",
    "        y_test = [y[idx] for idx in test_indices]\n",
    "        y_pred = predict(X_train, y_train, X_test, k_neighbors)\n",
    "        precision, recall, f1, accuracy, conf_matrix = evaluate(y_test, y_pred)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        confusion_matrices.append(conf_matrix)\n",
    "    \n",
    "    avg_precision = sum(precision_scores) / k_folds\n",
    "    avg_recall = sum(recall_scores) / k_folds\n",
    "    avg_f1 = sum(f1_scores) / k_folds\n",
    "    avg_accuracy = sum(accuracy_scores) / k_folds\n",
    "    total_conf_matrix = [[sum(confusion_matrices[j][i][k] for j in range(k_folds)) for k in range(len(confusion_matrices[0][0]))] for i in range(len(confusion_matrices[0]))]\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1, avg_accuracy, total_conf_matrix\n",
    "\n",
    "def print_cross_validation_metrics(avg_metrics):\n",
    "    precision, recall, f1, accuracy, conf_matrix = avg_metrics\n",
    "    print_evaluation_metrics(precision, recall, f1, accuracy, conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d46018-22f1-4b53-96a3-18e8c6c67fcd",
   "metadata": {},
   "source": [
    "##  Run and Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc35f984-2b2a-43c4-a94c-2aeeee24483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3, without cross-validation:\n",
      "Without built-in functions:\n",
      "Precision: 0.9333333333333333\n",
      "Recall: 0.9333333333333333\n",
      "F1-Score: 0.9333333333333333\n",
      "Accuracy: 0.9333333333333333\n",
      "Confusion Matrix:\n",
      "[8, 0, 0]\n",
      "[0, 8, 2]\n",
      "[0, 0, 12]\n",
      "\n",
      "K = 3, with 10-fold cross-validation:\n",
      "Without built-in functions:\n",
      "Precision: 0.9666666666666668\n",
      "Recall: 0.9666666666666668\n",
      "F1-Score: 0.9666666666666668\n",
      "Accuracy: 0.9666666666666668\n",
      "Confusion Matrix:\n",
      "[50, 0, 0]\n",
      "[0, 47, 3]\n",
      "[0, 2, 48]\n",
      "\n",
      "K = 5, without cross-validation:\n",
      "Without built-in functions:\n",
      "Precision: 0.9666666666666667\n",
      "Recall: 0.9666666666666667\n",
      "F1-Score: 0.9666666666666667\n",
      "Accuracy: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      "[8, 0, 0]\n",
      "[0, 9, 1]\n",
      "[0, 0, 12]\n",
      "\n",
      "K = 5, with 10-fold cross-validation:\n",
      "Without built-in functions:\n",
      "Precision: 0.9733333333333334\n",
      "Recall: 0.9733333333333334\n",
      "F1-Score: 0.9733333333333334\n",
      "Accuracy: 0.9733333333333334\n",
      "Confusion Matrix:\n",
      "[50, 0, 0]\n",
      "[0, 47, 3]\n",
      "[0, 1, 49]\n"
     ]
    }
   ],
   "source": [
    "# K = 3 without cross-validation\n",
    "print(\"K = 3, without cross-validation:\")\n",
    "y_pred = predict(X_train, y_train, X_test, k=3)\n",
    "metrics = evaluate(y_test, y_pred)\n",
    "print(\"Without built-in functions:\")\n",
    "print_evaluation_metrics(*metrics)\n",
    "\n",
    "# K = 3 with 10-fold cross-validation\n",
    "print(\"\\nK = 3, with 10-fold cross-validation:\")\n",
    "avg_metrics = cross_validate(X, y, k_neighbors=3, k_folds=10)\n",
    "print(\"Without built-in functions:\")\n",
    "print_cross_validation_metrics(avg_metrics)\n",
    "\n",
    "# K = 5 without cross-validation\n",
    "print(\"\\nK = 5, without cross-validation:\")\n",
    "y_pred = predict(X_train, y_train, X_test, k=5)\n",
    "metrics = evaluate(y_test, y_pred)\n",
    "print(\"Without built-in functions:\")\n",
    "print_evaluation_metrics(*metrics)\n",
    "\n",
    "# K = 5 with 10-fold cross-validation\n",
    "print(\"\\nK = 5, with 10-fold cross-validation:\")\n",
    "avg_metrics = cross_validate(X, y, k_neighbors=5, k_folds=10)\n",
    "print(\"Without built-in functions:\")\n",
    "print_cross_validation_metrics(avg_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de71d5-367d-463c-ae7d-fada6b81b4b6",
   "metadata": {},
   "source": [
    "# Library Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff62ab5-db20-4b35-bc59-c83520a021d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the IRIS dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "X_df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "y_df = pd.DataFrame(y, columns=['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7c332ae-afae-4da4-8e09-228cc5bb579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46312b62-371e-4a9d-8ed1-b7b382c6b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    return precision, recall, f1, accuracy, conf_matrix\n",
    "\n",
    "def print_evaluation_metrics(precision, recall, f1, accuracy, conf_matrix):\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4948ebbf-b5eb-4a03-bcb5-f8f83d118794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3, without cross-validation:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "K = 5, without cross-validation:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "# K=3 without cross-validation\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_3.fit(X_train, y_train)\n",
    "y_pred_3 = knn_3.predict(X_test)\n",
    "print(\"K = 3, without cross-validation:\")\n",
    "metrics_3 = evaluate(y_test, y_pred_3)\n",
    "print_evaluation_metrics(*metrics_3)\n",
    "\n",
    "# K=5 without cross-validation\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_5.fit(X_train, y_train)\n",
    "y_pred_5 = knn_5.predict(X_test)\n",
    "print(\"\\nK = 5, without cross-validation:\")\n",
    "metrics_5 = evaluate(y_test, y_pred_5)\n",
    "print_evaluation_metrics(*metrics_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d58bc3fc-310f-4068-976a-1d03144657f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K = 3, with 10-fold cross-validation:\n",
      "Precision: 0.9667867146858743\n",
      "Recall: 0.9666666666666667\n",
      "F1-Score: 0.9666633329999667\n",
      "Accuracy: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      "[[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  2 48]]\n",
      "\n",
      "K = 5, with 10-fold cross-validation:\n",
      "Precision: 0.9677505687140372\n",
      "Recall: 0.9666666666666667\n",
      "F1-Score: 0.9666366396423448\n",
      "Accuracy: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      "[[50  0  0]\n",
      " [ 0 46  4]\n",
      " [ 0  1 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def cross_validate_knn(X, y, k_neighbors, k_folds=10):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
    "    y_pred = cross_val_predict(knn, X, y, cv=k_folds)\n",
    "    precision, recall, f1, accuracy, conf_matrix = evaluate(y, y_pred)\n",
    "    return precision, recall, f1, accuracy, conf_matrix\n",
    "\n",
    "# K=3 with 10-fold cross-validation\n",
    "print(\"\\nK = 3, with 10-fold cross-validation:\")\n",
    "avg_metrics_3_cv = cross_validate_knn(X, y, k_neighbors=3, k_folds=10)\n",
    "print_evaluation_metrics(*avg_metrics_3_cv)\n",
    "\n",
    "# K=5 with 10-fold cross-validation\n",
    "print(\"\\nK = 5, with 10-fold cross-validation:\")\n",
    "avg_metrics_5_cv = cross_validate_knn(X, y, k_neighbors=5, k_folds=10)\n",
    "print_evaluation_metrics(*avg_metrics_5_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79833306-3215-4d57-aae0-bf9a186a1ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d7ab7-c415-4104-80ff-cd3083eae5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0402ede-ac18-48ce-ac2a-6d12d1c24210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fec00d-60e2-408a-87e7-5a18df2d20db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b70027-757e-4ff6-a72e-9dd2cf3a9911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
